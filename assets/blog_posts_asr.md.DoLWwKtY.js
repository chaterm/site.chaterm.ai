import{_ as t,c as o,o as a,a1 as n}from"./chunks/framework.DDNAyvCW.js";const i="/assets/asr01.Brst6PuI.png",r="/assets/asr02.BhY3z4jf.png",s="/assets/asr03.DiC-DB3I.png",c="/assets/asr04.D1ps4h9W.png",l="/assets/asr05.CkWVRVkh.svg",d="/assets/asr06.BzVJhcCi.png",h="/assets/asr07.CIV7obLP.gif",v=JSON.parse('{"title":"How Chaterm precisely operate Kubernetes using ASR + LLM","description":"","frontmatter":{"title":"How Chaterm precisely operate Kubernetes using ASR + LLM","author":"DYin","date":"2026-2-6","comment":false,"category":"Technical","tags":["ASR","Kubernetes","LLM","AI","Docker"],"blog":"post","aside":"left","sidebar":false,"prev":false,"next":false},"headers":[],"relativePath":"blog/posts/asr.md","filePath":"blog/posts/asr.md"}'),p={name:"blog/posts/asr.md"};function u(g,e,m,b,f,y){return a(),o("div",null,e[0]||(e[0]=[n('<p>This article introduces how Chaterm achieves high-precision recognition of various terminal operations and Kubernetes commands on mobile devices through a two-layer architecture of ASR hotword list + LLM error correction.</p><p>It also introduces the design paradigm of Chaterm&#39;s prompt word engineering, including: clear role definition, clear task boundary constraints, structured processing flow, and few-shot examples, to improve the accuracy and consistency of model output.</p><hr><br> As a programmer, after a year of hard work, even going home for the Spring Festival isn&#39;t always easy. There&#39;s the train journey home for family reunions, blind dates arranged by parents, giving money at classmates&#39; weddings, and being bombarded with questions about salary from relatives. But the most terrifying thing is the sudden – &quot;[P0 Level Alert] Core Transaction Service Timeout!&quot; <p>As a programmer myself, I deeply empathize with these scenarios every time I witness them.</p><p><img src="'+i+'" alt=""></p><p>To ensure a good New Year, we created a firefighting tool capable of operating the production system with one hand even in extreme environments!</p><p>However, the first challenge we encountered was how to accurately convert traditional speech recognition into 100% accurate operating commands for various cloud platform APIs, or Kubernetes and Linux systems.</p><hr><h2 id="part-1-technical-challenges-of-kubernetes-command-speech-recognition" tabindex="-1">Part 1: Technical Challenges of Kubernetes Command Speech Recognition <a class="header-anchor" href="#part-1-technical-challenges-of-kubernetes-command-speech-recognition" aria-label="Permalink to &quot;Part 1: Technical Challenges of Kubernetes Command Speech Recognition&quot;">​</a></h2><h3 id="_1-1-background" tabindex="-1">1.1 Background <a class="header-anchor" href="#_1-1-background" aria-label="Permalink to &quot;1.1 Background&quot;">​</a></h3><p>The first issue to address is that engineers frequently need to execute various commands and parameters quickly via voice on mobile devices, such as <code>kubectl</code>. On mobile devices, this process faces a significant user experience problem: <strong>typing complex Kubernetes commands on a mobile phone&#39;s virtual keyboard is extremely painful and inefficient.</strong></p><p><strong>Voice input</strong> is a natural solution. However, traditional ASR (Automatic Speech Recognition) systems face serious challenges when processing Kubernetes commands:</p><table tabindex="0"><thead><tr><th>Challenge Type</th><th>Specific Manifestations</th><th>Example</th></tr></thead><tbody><tr><td><strong>Property Noun Recognition</strong></td><td>Command verbs are recognized as homophones</td><td><code>kubectl</code> → &quot;cool B control&quot;, &quot;cube ctl&quot;</td></tr><tr><td><strong>Complex Parameter Combinations</strong></td><td>Long command parameters are missing or misplaced</td><td><code>kubectl get pods -n default -o wide</code> → &quot;kubectl get pods default wide&quot;</td></tr><tr><td><strong>Resource Type Confusion</strong></td><td>Ambiguity caused by mixing abbreviations and full names</td><td><code>svc</code> vs <code>services</code>, <code>deploy</code> vs <code>deployments</code></td></tr><tr><td><strong>Namespace Parameters</strong></td><td>Short parameters are easily ignored</td><td><code>-n</code>, <code>--namespace</code> are swallowed or misrecognized</td></tr><tr><td><strong>Special Character Handling</strong></td><td>Symbols cannot be correctly recognized</td><td>Symbols such as <code>-</code>, <code>--</code>, <code>/</code> are missing</td></tr></tbody></table><h3 id="_1-2-limitations-of-traditional-solutions" tabindex="-1">1.2 Limitations of Traditional Solutions <a class="header-anchor" href="#_1-2-limitations-of-traditional-solutions" aria-label="Permalink to &quot;1.2 Limitations of Traditional Solutions&quot;">​</a></h3><p>Traditional speech recognition solutions mainly suffer from the following problems:</p><ol><li><p><strong>Insufficient generalization ability of general models:</strong> ASR models are trained on massive general corpora, resulting in limited coverage of specialized terminology in vertical domains.</p></li><li><p><strong>Out-of-Vocabulary (OOV) problem:</strong> Words such as <code>kubectl</code>, <code>namespace</code>, and <code>deployment</code> are not in the regular vocabulary.</p></li><li><p><strong>Lack of contextual understanding:</strong> Inability to understand command semantics, making intelligent completion and error correction difficult.</p></li><li><p><strong>Difficulty in recognizing mixed Chinese and English:</strong> K8S commands involve a large amount of English terminology mixed with spoken Chinese.</p></li></ol><h3 id="_1-3-chaterm-s-solution" tabindex="-1">1.3 Chaterm&#39;s Solution <a class="header-anchor" href="#_1-3-chaterm-s-solution" aria-label="Permalink to &quot;1.3 Chaterm&#39;s Solution&quot;">​</a></h3><p><strong>Chaterm achieves near 100% accuracy in recognizing K8S commands through a two-layer architecture design:</strong></p><hr><p><img src="'+r+'" alt=""></p><hr><h2 id="ii-system-architecture-design" tabindex="-1">II. System Architecture Design <a class="header-anchor" href="#ii-system-architecture-design" aria-label="Permalink to &quot;II. System Architecture Design&quot;">​</a></h2><h3 id="_2-1-core-component-architecture" tabindex="-1">2.1 Core Component Architecture <a class="header-anchor" href="#_2-1-core-component-architecture" aria-label="Permalink to &quot;2.1 Core Component Architecture&quot;">​</a></h3><p>At the implementation level of core components, the overall architecture follows the design pattern of &quot;client → gateway → external service&quot;, with bidirectional data interaction between each layer via the WebSocket protocol.</p><p><img src="'+s+'" alt=""></p><br><p><strong>Flutter Mobile App:</strong> The architecture is divided into two main modules: <strong>User Interface (UI) components</strong> and <strong>Service Layer</strong>. At the UI level, the VoiceInputButton component provides a voice input interface and uses WaveAnimation to provide real-time feedback on the user&#39;s operation status. At the service layer, AudioStreamService handles the acquisition of PCM format audio streams, while SpeechService encapsulates the data transmission logic based on the WebSocket protocol. Meanwhile, the VoiceCommandCorrection module encapsulates a carefully designed Prompt, enabling the use of a Large Language Model (LLM) to correct voice commands.</p><p><strong>Gateway Layer:</strong> The backend services are built using Go. Its core components include a WebSocket handler and an authentication module. Specifically, during connection establishment, a parameter named <code>hotword_id</code> is appended, allowing the Automatic Speech Recognition (ASR) system to load a corresponding hotword list, achieving a &quot;one-time handshake, end-to-end optimization&quot; effect.</p><p><strong>External Service System:</strong> This system primarily integrates two key capabilities: first, it utilizes Tencent Cloud&#39;s real-time speech recognition engine, which supports audio processing capabilities such as hotword lists, replacement words, and weight enhancement; second, it integrates LLM services to provide high-level semantic understanding and instruction generation capabilities. These two technologies work together to improve the overall performance of the system.</p><h3 id="_2-2-full-process-analysis-of-voice-execution" tabindex="-1">2.2 Full Process Analysis of Voice Execution <a class="header-anchor" href="#_2-2-full-process-analysis-of-voice-execution" aria-label="Permalink to &quot;2.2 Full Process Analysis of Voice Execution&quot;">​</a></h3><p><img src="'+c+`" alt=""></p><br><p><strong>Voice-Driven Execution of O&amp;M Commands:</strong> Taking <code>kubectl get pods -A</code> as an example</p><p>This process demonstrates how the system handles recognition errors and ultimately executes commands accurately when a user directly utters them:</p><p><strong>1. Phase One: Real-Time Voice Acquisition and Transmission</strong></p><ul><li><p><strong>Command Input:</strong> The user presses a button in the Flutter client and utters the command: &quot;kubectl get pods -A&quot;.</p></li><li><p><strong>Audio Processing:</strong> The client&#39;s AudioStreamService acquires 16kHz/16bit PCM audio frames in real time.</p></li></ul><p><strong>2. Phase Two: Low-Latency ASR Real-Time Feedback</strong></p><ul><li><p><strong>Communication Link:</strong> The Flutter client connects to the Go backend via a WebSocket interface (/v1/speech/asr). The backend synchronously establishes a connection with Tencent Cloud ASR, carrying <code>hotword_id</code> (hotword list) to enhance the recognition of technical terms.</p></li><li><p><strong>Recognition Challenge:</strong> Since words like &quot;kubectl&quot; are easily misrecognized in non-operations contexts, the system enhances accuracy by mounting an operations hotword list (hotword_id).</p></li><li><p><strong>Real-time Preview:</strong> ASR returns intermediate recognition results in real-time, pushed from the backend to the client. Users can see the real-time recognized text on the interface, such as: &quot;q... q coins... cube control...&quot;.</p></li></ul><p><strong>3. Phase Three: LLM Semantic Correction (Core Component)</strong></p><ul><li><p><strong>Original Text Acquisition:</strong> After speech recognition ends, the final text returned by ASR may contain significant errors, such as: &quot;cube control get pods Dash a&quot; (mishearing &quot;kubectl&quot; as &quot;cube control&quot; and &quot;-A&quot; as &quot;Dash a&quot;).</p></li><li><p><strong>Calling LLM:</strong> Calling the VoiceCommandCorrection interface.</p></li><li><p><strong>Correction Output:</strong> LLM, combined with the operations knowledge base, performs semantic analysis to accurately correct the above-mentioned confusing text to the standard: &quot;kubectl get pods -A&quot;.</p></li></ul><p><strong>4. Phase Four: Terminal Writing and Manual Confirmation</strong></p><ul><li><p><strong>Terminal Writing:</strong> The corrected standard command is sent to the input box.</p></li><li><p><strong>Final Check:</strong> For security reasons, the command will not run immediately. Instead, it will wait for the user&#39;s secondary confirmation on the client before being officially triggered and executed in the terminal environment.</p></li></ul><hr><h2 id="iii-first-layer-accurate-asr-hotword-list-recognition" tabindex="-1">III. First Layer: Accurate ASR Hotword List Recognition <a class="header-anchor" href="#iii-first-layer-accurate-asr-hotword-list-recognition" aria-label="Permalink to &quot;III. First Layer: Accurate ASR Hotword List Recognition&quot;">​</a></h2><h3 id="_3-1-hotword-list-technical-principles" tabindex="-1">3.1 Hotword List Technical Principles <a class="header-anchor" href="#_3-1-hotword-list-technical-principles" aria-label="Permalink to &quot;3.1 Hotword List Technical Principles&quot;">​</a></h3><p><strong>The Hotword List</strong> is a domain adaptation mechanism provided by the ASR system. By increasing the prior probability of specific words during the decoding process, it significantly improves the recognition accuracy of target words.</p><h4 id="_3-1-1-why-is-a-hotword-list-needed" tabindex="-1">3.1.1 Why is a Hotword List Needed? <a class="header-anchor" href="#_3-1-1-why-is-a-hotword-list-needed" aria-label="Permalink to &quot;3.1.1 Why is a Hotword List Needed?&quot;">​</a></h4><p>General ASR models are trained on massive amounts of everyday language corpora, resulting in insufficient coverage of specialized terminology and a <strong>OOV (Out-of-Vocabulary) problem</strong>. When a user says &quot;kubectl,&quot; the model tends to output near-homophones seen during training (such as &quot;CoolB Control&quot;) rather than low-frequency specialized terms.</p><h4 id="_3-1-2-working-principle" tabindex="-1">3.1.2 Working Principle <a class="header-anchor" href="#_3-1-2-working-principle" aria-label="Permalink to &quot;3.1.2 Working Principle&quot;">​</a></h4><p>During ASR decoding, the output probability of each candidate word is calculated. <strong>The Hotword List changes the decoding result by applying probability bonuses to specific words:</strong></p><div class="language-plain vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">plain</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span>No hot word list:                     With hot word list (kubectl weight 100):</span></span>
<span class="line"><span>─────────────────────                 ─────────────────────</span></span>
<span class="line"><span>&quot;coolB control&quot; P=0.35 ← Selected    &quot;kubectl&quot; P=0.15×5=0.75 ← Selected</span></span>
<span class="line"><span>&quot;kubectl&quot; P=0.15                     &quot;CoolB control&quot; P=0.35</span></span></code></pre></div><p>Mathematical Expression: <code>P&#39;(hot word) = P(hot word) × boost_factor</code></p><p>The higher the weight, the larger the boost_factor, and the higher the probability of the hot word winning in homonym competition.</p><h4 id="_3-1-3-hot-word-weight-settings" tabindex="-1">3.1.3 Hot Word Weight Settings <a class="header-anchor" href="#_3-1-3-hot-word-weight-settings" aria-label="Permalink to &quot;3.1.3 Hot Word Weight Settings&quot;">​</a></h4><p>Cloud ASR supports a weight range of 1-11,100:</p><table tabindex="0"><thead><tr><th>Weight Range</th><th>Applicable Scenarios</th><th>Description</th></tr></thead><tbody><tr><td>1-10</td><td>Regular Business Vocabulary</td><td>Slight Improvement, Avoiding Overfitting</td></tr><tr><td>11</td><td>Technical Terminology</td><td>Moderate Improvement, Balancing Accuracy and Generalization</td></tr><tr><td>100</td><td>Core Keywords</td><td>Forced Recognition, Applicable to OOV Vocabulary</td></tr></tbody></table><p><strong>In Kubernetes (K8S) command scenarios, a weight of 100 is used</strong> to ensure that core terms such as <code>kubectl</code> and <code>namespace</code> are prioritized for recognition.</p><h3 id="_3-2-kubernetes-hot-topic-table-design" tabindex="-1">3.2 Kubernetes Hot Topic Table Design <a class="header-anchor" href="#_3-2-kubernetes-hot-topic-table-design" aria-label="Permalink to &quot;3.2 Kubernetes Hot Topic Table Design&quot;">​</a></h3><p>We have built a Kubernetes-specific hot topic table covering the following categories:</p><h4 id="_3-2-1-core-command-verbs" tabindex="-1">3.2.1 Core Command Verbs <a class="header-anchor" href="#_3-2-1-core-command-verbs" aria-label="Permalink to &quot;3.2.1 Core Command Verbs&quot;">​</a></h4><div class="language-latex vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">latex</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">kubectl|100</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">kubectl get|100</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">cube control|100</span></span></code></pre></div><h4 id="_3-2-2-resource-type-vocabulary" tabindex="-1">3.2.2 Resource Type Vocabulary <a class="header-anchor" href="#_3-2-2-resource-type-vocabulary" aria-label="Permalink to &quot;3.2.2 Resource Type Vocabulary&quot;">​</a></h4><div class="language-latex vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">latex</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">pods|100</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">pod|100</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">services|100</span></span></code></pre></div><h4 id="_3-2-3-commonly-used-parameter-combinations" tabindex="-1">3.2.3 Commonly Used Parameter Combinations <a class="header-anchor" href="#_3-2-3-commonly-used-parameter-combinations" aria-label="Permalink to &quot;3.2.3 Commonly Used Parameter Combinations&quot;">​</a></h4><div class="language-latex vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">latex</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">\`\`n|100</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">\`\`n default|100</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">\`\`\` namespace|100</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">#### 3.2.4 Complete Command Template</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">\`\`\`latex</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">kubectl get pods|100</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">kubectl get pods -A|100</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">kubectl get pods -n default|100</span></span></code></pre></div><h3 id="_3-3-hot-topic-list-integration-process" tabindex="-1">3.3 Hot Topic List Integration Process <a class="header-anchor" href="#_3-3-hot-topic-list-integration-process" aria-label="Permalink to &quot;3.3 Hot Topic List Integration Process&quot;">​</a></h3><p><img src="`+l+'" alt=""></p><h2 id="iv-second-layer-llm-intelligent-error-correction" tabindex="-1">IV. Second Layer: LLM Intelligent Error Correction <a class="header-anchor" href="#iv-second-layer-llm-intelligent-error-correction" aria-label="Permalink to &quot;IV. Second Layer: LLM Intelligent Error Correction&quot;">​</a></h2><h3 id="_4-1-the-necessity-of-llm-error-correction" tabindex="-1">4.1 The Necessity of LLM Error Correction <a class="header-anchor" href="#_4-1-the-necessity-of-llm-error-correction" aria-label="Permalink to &quot;4.1 The Necessity of LLM Error Correction&quot;">​</a></h3><p>Although the hotword list significantly improves the recognition rate of technical terms, ASR output may still have the following problems:</p><ol><li><p><strong>Residual Homophone Errors</strong>: Some words are still recognized as near-homophones (e.g., &quot;kube ctl&quot;).</p></li><li><p><strong>Natural Language Expressions</strong>: Users may say &quot;View all pods&quot; instead of &quot;kubectl get pods -A&quot;.</p></li><li><p><strong>Incorrect Parameter Order</strong>: &quot;-n default&quot; may appear in the middle of the command.</p></li><li><p><strong>Incorrect Formatting</strong>: Missing necessary spaces, hyphens, etc.</p></li></ol><p><strong>The Role of the LLM Layer</strong>: As a semantic understanding layer, it converts the raw output of ASR (natural language, homophones, incomplete commands) into <strong>standard, executable Kubernetes commands</strong>.</p><h3 id="_4-2-prompt-engineering-design-the-industry-standard-design-paradigm-for-prompt-engineering-generally-includes-clear-role-definition-clear-task-boundary-constraints-structured-processing-flow-and-high-quality-few-shot-examples-a-well-designed-prompt-can-significantly-improve-the-accuracy-and-consistency-of-model-output" tabindex="-1">4.2 Prompt Engineering Design The industry-standard design paradigm for <strong>Prompt Engineering</strong> generally includes: clear role definition, clear task boundary constraints, structured processing flow, and high-quality <strong>Few-shot examples</strong>. A well-designed prompt can significantly improve the accuracy and consistency of model output. <a class="header-anchor" href="#_4-2-prompt-engineering-design-the-industry-standard-design-paradigm-for-prompt-engineering-generally-includes-clear-role-definition-clear-task-boundary-constraints-structured-processing-flow-and-high-quality-few-shot-examples-a-well-designed-prompt-can-significantly-improve-the-accuracy-and-consistency-of-model-output" aria-label="Permalink to &quot;4.2 Prompt Engineering Design The industry-standard design paradigm for **Prompt Engineering** generally includes: clear role definition, clear task boundary constraints, structured processing flow, and high-quality **Few-shot examples**. A well-designed prompt can significantly improve the accuracy and consistency of model output.&quot;">​</a></h3><p>In the voice command correction scenario of Chaterm, we followed the above principles and designed the following System Prompt structure:</p><ul><li><p><strong>Role Definition</strong>: Positioning the model as a &quot;voice-to-terminal command assistant,&quot; clearly defining its responsibilities—only performing command conversion, without providing additional explanations or suggestions.</p></li><li><p><strong>Core Principle</strong>: Emphasizing a conservative strategy, i.e., &quot;no fabrication&quot;—not adding parameters not mentioned by the user, avoiding erroneous commands caused by excessive model inference.</p></li><li><p><strong>Processing Flow</strong>: Executed in two stages: first, correcting homophonic errors remaining from ASR (text correction), then performing K8s command format standardization (structural completion).</p></li><li><p><strong>Correction Rules</strong>: Through continuous debugging, knowledge from areas such as homophonic mapping tables, symbol standardization rules, and abbreviation expansion rules is further integrated to provide the model with clear conversion criteria.</p></li><li><p><strong>Few-shot Examples</strong>: Covering typical scenarios such as homophonic error correction, natural language conversion, and parameter normalization, examples guide the model to output in the expected format.</p></li></ul><p><img src="'+d+'" alt=""></p><h3 id="_4-3-llm-error-correction-effect" tabindex="-1">4.3 LLM Error Correction Effect <a class="header-anchor" href="#_4-3-llm-error-correction-effect" aria-label="Permalink to &quot;4.3 LLM Error Correction Effect&quot;">​</a></h3><h4 id="typical-error-correction-examples" tabindex="-1">Typical Error Correction Examples <a class="header-anchor" href="#typical-error-correction-examples" aria-label="Permalink to &quot;Typical Error Correction Examples&quot;">​</a></h4><table tabindex="0"><thead><tr><th>Scenario</th><th>ASR Raw Output</th><th>LLM Error Correction Output</th></tr></thead><tbody><tr><td>Phonetic Error Correction</td><td>&quot;cool B control get run&quot;</td><td>kubectl get pods</td></tr><tr><td>Natural Language Conversion</td><td>&quot;view all pods&quot;</td><td>kubectl get pods -A</td></tr><tr><td>Parameter Normalization</td><td>&quot;kubectl get pods bar n default&quot;</td><td>kubectl get pods -n default</td></tr><tr><td>Hybrid Error Correction</td><td>&quot;kube ctl describe of deployment nginx&quot;</td><td>kubectl describe deployment nginx</td></tr><tr><td>Resource Operation</td><td>&quot;delete nginx under default&quot;</td><td>kubectl delete pod nginx -n default</td></tr></tbody></table><hr><h2 id="v-real-world-case-demonstration" tabindex="-1">V. Real-world Case Demonstration <a class="header-anchor" href="#v-real-world-case-demonstration" aria-label="Permalink to &quot;V. Real-world Case Demonstration&quot;">​</a></h2><h3 id="case-recovering-the-payment-deployment-service-using-voice-input" tabindex="-1">Case: Recovering the payment-deployment service using voice input <a class="header-anchor" href="#case-recovering-the-payment-deployment-service-using-voice-input" aria-label="Permalink to &quot;Case: Recovering the payment-deployment service using voice input&quot;">​</a></h3><p><img src="'+h+'" alt=""></p><hr><h2 id="vi-summary" tabindex="-1">VI. Summary <a class="header-anchor" href="#vi-summary" aria-label="Permalink to &quot;VI. Summary&quot;">​</a></h2><p>Through a two-layer architecture of <strong>ASR and hotword enhancement + LLM error correction</strong>, Chatem achieves near 100% accurate recognition of K8S commands:</p><ol><li><p><strong>Hotword Table</strong>: K8S command hotwords with weighted enhancement to ensure accurate recognition of proper nouns.</p></li><li><p><strong>LLM Error Correction</strong>: Converts natural language, homophones, and incomplete commands into standard K8S commands.</p></li><li><p><strong>End-to-End Optimization</strong>: Ensures accuracy across the entire process from voice input to command execution.</p></li><li><p><strong>Future Optimization Directions</strong>: Supports skipping LLM calls for short commands and high-confidence scenarios to achieve rapid local rule correction; optimizes the hotword table based on user habits for command history learning; supports saving frequently used command templates, etc.</p></li></ol><hr><h2 id="reference" tabindex="-1">Reference <a class="header-anchor" href="#reference" aria-label="Permalink to &quot;Reference&quot;">​</a></h2><ul><li>Website：<a href="https://chaterm.ai/" target="_blank" rel="noreferrer">https://chaterm.ai/</a></li><li>Github：<a href="https://github.com/chaterm/Chaterm" target="_blank" rel="noreferrer">https://github.com/chaterm/Chaterm</a></li></ul>',92)]))}const w=t(p,[["render",u]]);export{v as __pageData,w as default};
