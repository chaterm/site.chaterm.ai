import{_ as t,c as i,o,a1 as a}from"./chunks/framework.DDNAyvCW.js";const h=JSON.parse('{"title":"AI Settings","description":"","frontmatter":{},"headers":[],"relativePath":"docs/ai/settings/index.md","filePath":"docs/ai/settings/index.md"}'),n={name:"docs/ai/settings/index.md"};function l(r,e,s,d,c,u){return o(),i("div",null,e[0]||(e[0]=[a('<h1 id="ai-settings" tabindex="-1">AI Settings <a class="header-anchor" href="#ai-settings" aria-label="Permalink to &quot;AI Settings&quot;">​</a></h1><p>AI functionality is a core feature of Chaterm, providing intelligent operations assistant capabilities. This document will introduce how to use Chaterm&#39;s AI features. With proper configuration, you can fully utilize the AI assistant to improve work efficiency.</p><h2 id="ai-dialog-modes" tabindex="-1">AI Dialog Modes <a class="header-anchor" href="#ai-dialog-modes" aria-label="Permalink to &quot;AI Dialog Modes&quot;">​</a></h2><p>Click &quot;AI&quot; in the left menu to open the AI dialog panel. AI dialog modes support:</p><ul><li><strong>Natural Language Interaction</strong>: Use natural language to describe tasks, AI will understand your intent</li><li><strong>Multi-Tab Dialogs</strong>: Can conduct multiple AI dialogs simultaneously, each dialog is an independent session</li><li><strong>Context Understanding</strong>: AI will understand the current connected server environment and context information</li><li><strong>Task Planning</strong>: AI can plan complex operations tasks and execute them step by step</li></ul><h2 id="interaction-modes" tabindex="-1">Interaction Modes <a class="header-anchor" href="#interaction-modes" aria-label="Permalink to &quot;Interaction Modes&quot;">​</a></h2><p>AI supports three interaction modes:</p><h3 id="chat-mode" tabindex="-1">Chat Mode <a class="header-anchor" href="#chat-mode" aria-label="Permalink to &quot;Chat Mode&quot;">​</a></h3><ul><li><strong>Function</strong>: Dialog with AI, learning, brainstorming</li><li><strong>Features</strong>: Pure text conversation, similar to ChatGPT</li><li><strong>Use Cases</strong>: <ul><li>Knowledge learning and consultation</li><li>Brainstorming</li><li>Technical discussions</li><li>Code review</li></ul></li></ul><div class="warning custom-block"><p class="custom-block-title">Note</p><p>Terminal operations are not supported in this mode, cannot execute server commands.</p></div><h3 id="command-mode" tabindex="-1">Command Mode <a class="header-anchor" href="#command-mode" aria-label="Permalink to &quot;Command Mode&quot;">​</a></h3><ul><li><strong>Function</strong>: Execute related tasks in the current active terminal</li><li><strong>Features</strong>: <ul><li>All input and output are displayed in the terminal interface</li><li>AI will plan tasks and execute commands</li><li>Requires user confirmation before execution (no confirmation needed if auto-execute is enabled)</li></ul></li><li><strong>Use Cases</strong>: <ul><li>Command-line operations</li><li>Local task execution</li><li>Single terminal task processing</li></ul></li></ul><h3 id="agent-mode" tabindex="-1">Agent Mode <a class="header-anchor" href="#agent-mode" aria-label="Permalink to &quot;Agent Mode&quot;">​</a></h3><ul><li><strong>Function</strong>: Execute command queries on any host, troubleshoot errors, handle tasks, and more</li><li><strong>Features</strong>: <ul><li>Operation results are displayed in the AI content area</li><li>Supports fully automatic execution</li><li>Can @ multiple hosts for operations</li><li>AI will adjust strategy based on execution results and continue completing tasks</li></ul></li><li><strong>Use Cases</strong>: <ul><li>Multi-host task processing</li><li>System problem troubleshooting</li><li>Automated operations</li><li>Complex task planning</li></ul></li></ul><h2 id="create-new-dialog" tabindex="-1">Create New Dialog <a class="header-anchor" href="#create-new-dialog" aria-label="Permalink to &quot;Create New Dialog&quot;">​</a></h2><p>Click &quot;AI&quot; in the left menu to open the AI dialog panel. Click new dialog to configure:</p><ul><li><strong>Interaction Mode</strong>: Supports Chat, Command, Agent mode selection</li><li><strong>@Host</strong>: Agent mode supports @ multiple hosts for operations</li><li><strong>Model</strong>: Can select different models from the model list</li><li><strong>Upload File</strong>: Upload files, AI will read file content to understand and process tasks</li><li><strong>Voice Input</strong>: Supports user voice input</li></ul><h2 id="history-dialogs" tabindex="-1">History Dialogs <a class="header-anchor" href="#history-dialogs" aria-label="Permalink to &quot;History Dialogs&quot;">​</a></h2><p>The AI dialog panel supports history dialog management:</p><ul><li><strong>View History</strong>: Click the menu button in the top left to view all history dialogs</li><li><strong>Load Dialog</strong>: Click on history dialog items to load previous dialog content</li><li><strong>Delete Dialog</strong>: Can delete unwanted history dialogs</li><li><strong>Dialog Title</strong>: System automatically generates dialog titles, can also be manually modified</li><li><strong>Favorite Dialog</strong>: Can favorite needed history dialogs</li></ul><h2 id="export-chat" tabindex="-1">Export Chat <a class="header-anchor" href="#export-chat" aria-label="Permalink to &quot;Export Chat&quot;">​</a></h2><p>Supports exporting history dialogs for easy saving and sharing.</p><h2 id="model-settings" tabindex="-1">Model Settings <a class="header-anchor" href="#model-settings" aria-label="Permalink to &quot;Model Settings&quot;">​</a></h2><h3 id="select-api-provider" tabindex="-1">Select API Provider <a class="header-anchor" href="#select-api-provider" aria-label="Permalink to &quot;Select API Provider&quot;">​</a></h3><p>Chaterm currently supports the following AI service providers:</p><ul><li><strong>LiteLLM</strong>: Supports multiple model providers</li><li><strong>OpenAI</strong>: OpenAI compatible interface</li><li><strong>Bedrock</strong>: Amazon Bedrock</li><li><strong>DeepSeek</strong>: DeepSeek API</li><li><strong>Ollama</strong>: Local Ollama service</li></ul><h3 id="fill-in-authentication-information" tabindex="-1">Fill in Authentication Information <a class="header-anchor" href="#fill-in-authentication-information" aria-label="Permalink to &quot;Fill in Authentication Information&quot;">​</a></h3><p>Based on the API provider you selected, you need to fill in the corresponding authentication information:</p><ul><li><strong>OpenAI Compatible</strong>: Need to fill in API Key and service endpoint</li><li><strong>Amazon Bedrock</strong>: Need to configure AWS credentials</li><li><strong>DeepSeek</strong>: Need to fill in API Key</li><li><strong>LiteLLM</strong>: Configure according to specific provider</li><li><strong>Ollama</strong>: Configure local Ollama service address</li></ul><h3 id="select-model" tabindex="-1">Select Model <a class="header-anchor" href="#select-model" aria-label="Permalink to &quot;Select Model&quot;">​</a></h3><p>After filling in authentication information, you can:</p><ul><li>Directly enter model name</li><li>Or select available models from the dropdown list</li></ul><h3 id="verify-configuration" tabindex="-1">Verify Configuration <a class="header-anchor" href="#verify-configuration" aria-label="Permalink to &quot;Verify Configuration&quot;">​</a></h3><p>After completing the above settings:</p><ol><li>Click the &quot;Test Connection&quot; button on the interface</li><li>System will automatically test the connection</li><li>If configuration is correct, a success prompt will appear</li><li>You can now start using AI features</li></ol><div class="warning custom-block"><p class="custom-block-title">Notes</p><ul><li>Please ensure the authentication information filled in is accurate</li><li>It is recommended to regularly check the validity of API keys</li><li>If encountering connection issues, please check network status and service provider status</li><li>For detailed configuration, please refer to the <a href="/docs/ai/llms/">Model Configuration</a> documentation</li></ul></div><h2 id="prerequisites" tabindex="-1">Prerequisites <a class="header-anchor" href="#prerequisites" aria-label="Permalink to &quot;Prerequisites&quot;">​</a></h2><p>Before starting to use AI features, please ensure you have:</p><ul><li>Completed AI configuration in settings</li><li>Tested that AI connection status is normal</li><li>Selected an appropriate interaction mode</li></ul><p>For detailed configuration instructions, please refer to <a href="/docs/ai/llms/">Model Configuration</a> and <a href="/docs/ai/preferences/">AI Preferences</a>.</p>',40)]))}const p=t(n,[["render",l]]);export{h as __pageData,p as default};
